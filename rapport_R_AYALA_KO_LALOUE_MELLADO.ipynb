{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Projet de Machine Learning\n",
    "\n",
    "Notebook <b>R</b> avec les codes utilisés pour le rapport final.<br>\n",
    "Auteurs : Juan AYALA, Jeong Hwan KO, Alice LALOUE, Aldo MELLADO AGUILAR.<br>\n",
    "4A MA - Groupes A et B<br>\n",
    "2020 - 2021\n",
    "\n",
    "<p>Lien <a href=\"https://github.com/jayalabanda/projet-ML\">Github</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(corrplot)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(RColorBrewer)\n",
    "library(vcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenir les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data <- read.table(file = \"data/spotify-extr.txt\", header = T, sep = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description de l'ensemble du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(spotify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(spotify_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On n'a pas de valeurs manquantes donc on n'a pas besoin de les retravailler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables explicatives sont :\n",
    "* `valence` : la positivité de la chanson, vaut 1 si la chanson est très joyeuse, 0 sinon ;\n",
    "* `year` : année de sortie ;\n",
    "* `acousticness` : mesure \"l'acousticité\" de la chanson ;\n",
    "* `danceability` : mesure la \"dançabilite\" d'une chanson ;\n",
    "* `duration` : durée d'une chanson en millisecondes ;\n",
    "* `energy` : l'énergie de la chanson, vaut 1 si la chanson est très énergétique, 0 sinon ;\n",
    "* `intrumentalness` : taux d'instrumentalisation, vaut 1 s'il n'y a aucune voix présente dans la chanson, 0 sinon ; \n",
    "* `key` : tonalité de la musique (ex : A=la), ne prend pas en compte la distinction majeur/mineur ;\n",
    "* `liveness` : taux de prestation en live, vaut 1 si la chanson ne comporte que de la musique (sans sons à intérêts non-musicaux), 0 sinon ;\n",
    "* `loudness` : intensité sonore de la chanson\n",
    "* `mode` : variable binaire qui indique si la chanson commence par une progression d'accords majeure (1) ou non (0)\n",
    "* `speechiness` : taux de vocaux dans la chanson, vaut 1 si la chanson comporte de la voix tout le long, 0 sinon ;\n",
    "* `tempo` :  tempo de la chanson en beats par minute (bpm)\n",
    "\n",
    "Notre objectif consiste à prédire la valeur de `pop.class` et de `popularity`, c'est-à-dire la popularité d'une chanson, soit comme un entier entre 0 et 100, soit comme une classe $A$, $B$, $C$ ou $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(spotify_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre jeu de données, les variables qualitatives sont :\n",
    "* `pop.class`,\n",
    "* `key`,\n",
    "* `mode`.\n",
    "\n",
    "Le reste des variables sont quantitatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme les variables qualitatives en catégories pour mieux traiter les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data$pop.class <- factor(spotify_data$pop.class, ordered = TRUE)\n",
    "spotify_data$key <- factor(spotify_data$key)\n",
    "spotify_data$mode <- factor(spotify_data$mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.class <- spotify_data$pop.class\n",
    "key <- spotify_data$key\n",
    "mode <- spotify_data$mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(pop.class)\n",
    "levels(key)\n",
    "levels(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(spotify_data, class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses uni et multidimensionnelles\n",
    "\n",
    "## Variables qualitatives\n",
    "\n",
    "On commence par analyser les variables qualitatives `pop.class`, `key` et `mode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.qual <- spotify_data[, c(\"key\", \"mode\", \"pop.class\")]\n",
    "head(data.qual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Classe de popularité</b> (variable à prédire)\n",
    "\n",
    "Cette variable a été créée en amont de l'obtention des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage <- as.data.frame(table(pop.class))\n",
    "percentage$Freq <- percentage$Freq/sum(percentage$Freq)\n",
    "\n",
    "pop.class.count <- data.frame(name = levels(pop.class), value = percentage$Freq)\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "ggplot(data = pop.class.count, aes(x = name, y = value, fill = name)) +\n",
    "    geom_bar(stat = \"identity\", show.legend = FALSE) +\n",
    "    labs(x = \"Classe\", y = \"Pourcentage d'occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il y a une distribution uniforme des chansons par classe, sauf pour la classe `A`, qui comprend moins de 10% des chansons. Ceci risque de poser problème dans la suite en termes de prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Clé</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage <- as.data.frame(table(key))\n",
    "percentage$Freq <- sort(percentage$Freq/sum(percentage$Freq), decreasing = F)\n",
    "\n",
    "key.count <- data.frame(name = levels(key), value = percentage$Freq)\n",
    "\n",
    "options(repr.plot.width = 13, repr.plot.height = 6)\n",
    "\n",
    "ggplot(data = key.count, aes(x = name, y = value, fill = name)) +\n",
    "    geom_bar(stat = \"identity\", show.legend = FALSE) +\n",
    "    labs(x = \"Clé\", y = \"% d'occurences\") +\n",
    "    geom_text(aes(label = paste(round(value, 3) * 100, \"%\"), hjust = -0.2)) +\n",
    "    coord_flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata <- spotify_data %>%\n",
    "    group_by(key) %>%\n",
    "    summarize(n = n(), mean = mean(popularity), sd = sd(popularity)) %>%\n",
    "    mutate(se = sd/sqrt(n)) %>%\n",
    "    mutate(ic = se * qt((1 - 0.05)/2 + 0.5, n - 1))\n",
    "\n",
    "ggplot(plotdata, aes(x = key, y = mean, fill = key)) +\n",
    "    geom_bar(stat = \"identity\", show.legend = FALSE) +\n",
    "    geom_linerange(aes(x = key, ymin = mean - ic, ymax = mean + ic), size=1) +\n",
    "    labs(x = \"Clé\", y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variances de la popularité dans chacune des valeurs de `key` est petite donc nous n'avons pas besoin de transformer ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = spotify_data, aes(x = key, y = popularity, fill = key)) +\n",
    "    geom_boxplot(show.legend = FALSE) +\n",
    "    labs(x = \"Clé\", y = \"Popularité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la même façon, la distribution de la popularité reste plutôt uniforme par clé : les boîtes ont une taille similaire et la médiane est au même niveau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mode</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage <- as.data.frame(table(mode))\n",
    "percentage$Freq <- percentage$Freq/sum(percentage$Freq)\n",
    "\n",
    "mode.count <- data.frame(name = levels(mode), value = percentage$Freq)\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "ggplot(data = mode.count, aes(x = name, y = value, fill = name)) +\n",
    "    geom_bar(stat = \"identity\", show.legend = FALSE) +\n",
    "    labs(x = \"Mode\", y = \"Pourcentage d'occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribution de la variable `mode` est inégale : il y a 30% et 70% des chansons avec `mode` = 0 et `mode` = 1 respectivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata <- spotify_data %>%\n",
    "    group_by(mode) %>%\n",
    "    summarize(n = n(), mean = mean(popularity), sd = sd(popularity)) %>%\n",
    "    mutate(se = sd/sqrt(n)) %>%\n",
    "    mutate(ic = se * qt((1 - 0.05)/2 + 0.5, n - 1))\n",
    "\n",
    "ggplot(plotdata, aes(x = mode, y = mean, fill = mode)) +\n",
    "    geom_bar(stat = \"identity\", show.legend = FALSE) +\n",
    "    geom_linerange(aes(x = mode, ymin = mean - ic, ymax = mean + ic), size=1) +\n",
    "    labs(x = \"Mode\", y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par contre, la popularité est similaire selon le mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = spotify_data, aes(x = mode, y = popularity, fill = mode)) +\n",
    "    geom_boxplot(show.legend = FALSE) +\n",
    "    labs(x = \"Mode\", y = \"Popularité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regroupe toutes les variables qualitatives en un barplot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata <- spotify_data %>%\n",
    "    group_by(key, mode) %>%\n",
    "    summarize(n = n(), mean = mean(popularity), sd = sd(popularity)) %>%\n",
    "    mutate(se = sd/sqrt(n)) %>%\n",
    "    mutate(ic = se * qt((1 - 0.05)/2 + 0.5, n - 1))\n",
    "\n",
    "options(repr.plot.width = 15, repr.plot.height = 6)\n",
    "\n",
    "ggplot(data = plotdata, aes(x = key, y = mean, fill = key)) +\n",
    "    geom_bar(position=\"dodge\", stat=\"identity\", show.legend = FALSE) +\n",
    "    geom_linerange(aes(x = key, ymin = mean - ic, ymax = mean + ic), size=1) +\n",
    "    facet_wrap(~mode) +\n",
    "    theme(strip.background = element_rect(colour=\"black\", fill=\"white\",\n",
    "                                          size=1.5, linetype=\"solid\"),\n",
    "          strip.text.x = element_text(size=12, face=\"bold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 6)\n",
    "\n",
    "ggplot(data = spotify_data, aes(x = key, y = popularity, fill = key)) +\n",
    "    geom_boxplot(show.legend = FALSE) +\n",
    "    facet_wrap(~mode) +\n",
    "    theme(strip.background = element_rect(colour=\"black\", fill=\"white\",\n",
    "                                          size=1.5, linetype=\"solid\"),\n",
    "          strip.text.x = element_text(size=12, face=\"bold\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables quantitatives\n",
    "\n",
    "On commence par visualiser la corrélation entre les variables quantitatives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.quant <- spotify_data[, -c(8, 11, 15)]\n",
    "colnames(data.quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggcorrplot)\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 12)\n",
    "\n",
    "M <- cor(data.quant)\n",
    "ggcorrplot(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique nous montre qu'il y a certaines variables qui ont une forte corrélation. Par exemple, il y a une forte corrélation négative entre les variables `energy` et `acousticness`. Cela a du sens vu que les chansons acoustiques sont plus tranquilles (moins énergiques) que celles qui ne sont pas acoustiques. De même, `energy` et `loudness` sont positivement corrélées, ce qui est attendu vu que les chansons bruyantes ont souvent plus d'énergie.\n",
    "<br>\n",
    "On voit aussi que plus une chanson est acoustique, moins elle est populaire, vu que les variables `acousticness` et `popularity` ont une forte corrélation négative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation <- sort(abs(M[, 10]), decreasing = T)\n",
    "series <- as.data.frame(correlation)\n",
    "\n",
    "print(\"Les variables les plus corrélées avec 'popularity' sont : \")\n",
    "for (row in rownames(series)) {\n",
    "    if (series[row, 1] >= 0.2 && series[row, 1] < 1) {\n",
    "        print(paste(row, round(series[row, 1], 2), \"(abs)\"))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (i in 1:12) {\n",
    "    vari <- data.quant[, i]\n",
    "    nf <- layout(mat = matrix(c(1, 2), 2, 1, byrow = TRUE), height = c(1, 3))\n",
    "    par(mar = c(5.1, 4.1, 1.1, 2.1))\n",
    "    boxplot(vari, horizontal = TRUE, xaxt = \"n\", outline = F, col = \"#5975A4\")\n",
    "    hist(vari, main = paste(\"Histogram of\", colnames(data.quant)[i], sep = \" \"), \n",
    "        breaks = ifelse(i == 2, 100, 50), xlab = colnames(data.quant)[i], freq = F, \n",
    "        col = \"#4FABBC\")\n",
    "    lines(density(vari))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une étude plus approfondie de chaque variable quantitative :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Acousticness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.data <- as.data.frame(spotify_data %>%\n",
    "    group_by(acousticness) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "ggplot(ax.data, aes(x = acousticness, y = popularity)) +\n",
    "    geom_point(color = \"blue\", size = 4) +\n",
    "    labs(y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Danceability</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.data <- as.data.frame(spotify_data %>%\n",
    "    group_by(danceability) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "ggplot(ax.data, aes(x = danceability, y = popularity)) +\n",
    "    geom_point(color = \"blue\", size = 4) +\n",
    "    labs(y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Duration</b>\n",
    "\n",
    "On convertit la durée des chansons en minutes pour en tirer plus d'informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data$duration <- spotify_data$duration / 60000\n",
    "summary(spotify_data$duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = spotify_data, aes(x = duration)) +\n",
    "    geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 60) +\n",
    "    labs(x = \"duration (mins)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la chanson la plus longue dans le jeu de données dure 45 minutes, donc on choisit de séparer les chansons longues de chansons courtes au seuil de 7 minutes pour mieux voir les durées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long.songs <- spotify_data[spotify_data$duration > 7, ]\n",
    "short.songs <- spotify_data[spotify_data$duration <= 7, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(grid)\n",
    "library(gridExtra)\n",
    "\n",
    "p1 <- ggplot(data = short.songs, aes(x = duration)) +\n",
    "        geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 60) +\n",
    "        labs(x = \"duration (mins)\")\n",
    "\n",
    "p2 <- ggplot(data = long.songs, aes(x = duration)) +\n",
    "        geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 50) +\n",
    "        labs(x = \"duration (mins)\")\n",
    "\n",
    "grid.arrange(p1, p2, nrow = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.data <- as.data.frame(short.songs %>%\n",
    "    group_by(duration) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "ax2.data <- as.data.frame(long.songs %>%\n",
    "    group_by(duration) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "p1 <- ggplot(ax1.data, aes(x = duration, y = popularity)) +\n",
    "        geom_point(color = \"blue\", size = 4, alpha = .5) +\n",
    "        labs(title = \"Chansons courtes\", y = \"Popularité moyenne\") +\n",
    "        theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "p2 <- ggplot(ax2.data, aes(x = duration, y = popularity)) +\n",
    "        geom_point(color = \"orange\", size = 4) +\n",
    "        labs(title = \"Chansons longues\", y = \"\") +\n",
    "        theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "grid.arrange(p1, p2, nrow = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Energy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.data <- as.data.frame(short.songs %>%\n",
    "    group_by(energy) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "ggplot(ax.data, aes(x = energy, y = popularity)) +\n",
    "    geom_point(color = \"blue\", size = 4) +\n",
    "    labs(y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instrumentalness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(spotify_data$instrumentalness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(spotify_data[spotify_data$instrumentalness == 0, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 2806 chansons pour lesquelles `instrumentalness` vaut 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(vioplot)\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "inst.data <- spotify_data$instrumentalness\n",
    "vioplot(inst.data, horizontal = TRUE, col = \"#7490C0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.data <- as.data.frame(spotify_data %>%\n",
    "    group_by(instrumentalness) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "ggplot(ax.data, aes(x = instrumentalness, y = popularity)) +\n",
    "    geom_point(color = \"blue\", size = 4) +\n",
    "    labs(y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Liveness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.data <- as.data.frame(short.songs %>%\n",
    "    group_by(liveness) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "ggplot(ax.data, aes(x = liveness, y = popularity)) +\n",
    "    geom_point(color = \"blue\", size = 4) +\n",
    "    labs(y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Popularity</b> (variable à prédire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 10)\n",
    "\n",
    "p1 <- ggplot(spotify_data, aes(x = popularity)) +\n",
    "        geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 50) +\n",
    "        scale_x_continuous(breaks = seq(0, 100, 20)) +\n",
    "        labs(x = \"\")\n",
    "\n",
    "p2 <- ggplot(spotify_data[spotify_data$popularity > 0, ], aes(x = popularity)) +\n",
    "        geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 50) +\n",
    "        scale_x_continuous(breaks = seq(0, 100, 20))\n",
    "\n",
    "grid.arrange(p1, p2, nrow = 2, heights=c(20, 20),\n",
    "             top = textGrob(\n",
    "                 \"Haut : Toutes les données\\nBas : Popularité > 0\",\n",
    "                 gp = gpar(fontsize = 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(spotify_data[spotify_data$popularity == 0, ])\n",
    "summary(spotify_data$popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il y a un nombre important de chansons ayant 0 comme popularité. En effet ces chansons sont proches de l'extraction de la base des données et donc leur popularité n'avait pas encore été déterminée.\n",
    "\n",
    "De plus, la valeur maximale de popularité est 93 et 50% des valeurs se trouvent entre 11 et 48. Ces éléments poseront des problèmes en termes de régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.data <- as.data.frame(spotify_data %>%\n",
    "    group_by(year) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "options(repr.plot.width = 15, repr.plot.height = 5)\n",
    "\n",
    "ggplot(data = ax.data, aes(x = year, y = popularity)) +\n",
    "    geom_line(colour = \"blue\", size = 1) +\n",
    "    scale_x_continuous(breaks = seq(1920, 2020, 5)) +\n",
    "    labs(y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tempo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(WVPlots)\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "\n",
    "ScatterHist(spotify_data, \"tempo\", \"popularity\", title = \"Tempo vs. Popularity\",\n",
    "            minimal_labels = FALSE, smoothmethod = \"none\", binwidth_x = 4,\n",
    "            binwidth_y = 4, point_alpha = 1, point_color = \"#4C72B0\",\n",
    "            hist_color = \"#7490C0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(spotify_data[spotify_data$tempo == 0, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il y a 13 chansons pour lesquelles `tempo` vaut 0 ce qui n'est pas possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected.tempo <- spotify_data[spotify_data$tempo > 0, ]$tempo\n",
    "summary(corrected.tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 6)\n",
    "\n",
    "ggplot(data = spotify_data, aes(x = tempo)) +\n",
    "    geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 200) +\n",
    "    geom_text(x = 5, y = 55, label = \"13 Outliers\", size = 5) +\n",
    "    geom_text(x = 135, y = 160, label = \"Valeurs sans 0\", size = 5) +\n",
    "    annotate(\"text\", x = 126, y = 40, label = \"Médiane\\ncorrigée\\n114.55\",\n",
    "             size = 5, color = \"green\", fontface = 2) +\n",
    "    geom_segment(aes(x = 114.55, y = 0, xend = 114.55, yend = 100),\n",
    "                 linetype = \"dashed\", color = \"green\", size = 2) +\n",
    "    geom_segment(aes(x = 35.37, y = 0, xend = 35.37, yend = 200),\n",
    "                 linetype = \"dashed\", color = \"orange\", size = 2) +\n",
    "    geom_segment(aes(x = 214.42, y = 0, xend = 214.42, yend = 200),\n",
    "                 linetype = \"dashed\", color = \"orange\", size = 2) +\n",
    "    geom_segment(aes(x = 0, y = 50, xend = 0, yend = 30),\n",
    "                 arrow = arrow(length = unit(0.5, \"cm\"))) +\n",
    "    geom_segment(aes(x = 35.37, y = 150, xend = 214.42, yend = 150),\n",
    "                 linetype = \"dashed\", color = \"red\", size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On replace les valeurs où `tempo` = 0 par la médiane dans la colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median <- median(spotify_data[spotify_data$tempo > 0, ]$tempo)\n",
    "median\n",
    "\n",
    "dat <- replace(spotify_data$tempo, spotify_data$tempo == 0, median)\n",
    "spotify_data$tempo <- dat\n",
    "summary(spotify_data$tempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Valence</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.data <- as.data.frame(short.songs %>%\n",
    "    group_by(valence) %>%\n",
    "    mutate(popularity = mean(popularity)))\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "ggplot(ax.data, aes(x = valence, y = popularity)) +\n",
    "    geom_point(color = \"blue\", size = 4) +\n",
    "    labs(y = \"Popularité moyenne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(spotify_data, aes(x = valence)) +\n",
    "    geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Year<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "\n",
    "ScatterHist(spotify_data, \"year\", \"popularity\", title = \"Popularity vs. Year\",\n",
    "            minimal_labels = FALSE, smoothmethod = \"none\", binwidth_x = 4,\n",
    "            binwidth_y = 4, point_alpha = 1, point_color = \"#4C72B0\",\n",
    "            hist_color = \"#7490C0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prétraitement de variables :</b>\n",
    "\n",
    "On normalise la variable `danceability` vu sa ressemblance à une loi gaussienne puis on la supprime :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spotify_data <- spotify_data %>%\n",
    "    mutate(\n",
    "        dance_norm = (danceability - mean(danceability)) / sd(danceability),\n",
    "        danceability = NULL\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "ggplot(data = spotify_data, aes(x = dance_norm)) +\n",
    "    geom_histogram(color = \"black\", fill = \"#7490C0\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(spotify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 20)\n",
    "pairs(~., data = data.quant, col = mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 20)\n",
    "pairs(~., data = data.quant, col = key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(factoextra)\n",
    "library(FactoMineR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.quant <- spotify_data[, -c(7, 10, 11, 14)]\n",
    "colnames(data.quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pca <- PCA(data.quant, scale.unit = T, graph = F, ncp = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig.val <- get_eig(data.pca)\n",
    "\n",
    "options(repr.plot.width = 16, repr.plot.height = 9)\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "bp1 <- barplot(eig.val[1:10, 2], ylab = \"Pourcentage de variance expliquée\",\n",
    "               ylim = c(0, 35), col = \"#4682B4\")\n",
    "text(bp1, eig.val[1:10, 2] + 2, labels = paste(round(eig.val[1:10, 2], 2), \"%\"))\n",
    "lines(bp1, eig.val[1:10, 2])\n",
    "\n",
    "bp2 <- barplot(eig.val[1:10, 3], ylab = \"Variance partagée\",\n",
    "               ylim = c(0, 105), col = \"#4682B4\")\n",
    "text(bp2, eig.val[1:10, 3] + 2, labels = paste(round(eig.val[1:10, 3], 1), \"%\"))\n",
    "lines(bp2, eig.val[1:10, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(data.pca$ind$coord)\n",
    "abline(h = 0, col = \"grey\", lty = \"dashed\", lwd = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds <- as.data.frame(data.pca$ind$coord)\n",
    "options(repr.plot.width = 12, repr.plot.height = 9)\n",
    "\n",
    "ggplot(inds, aes(inds[, 1], inds[, 2], colour = pop.class)) +\n",
    "    geom_point() +\n",
    "    labs(x = paste(\"Dim 1 (\", round(eig.val[1, 2], 1), \"%)\"),\n",
    "         y = paste(\"Dim 2 (\", round(eig.val[2, 2], 1), \"%)\")) +\n",
    "    scale_color_brewer(palette=\"Set1\") +\n",
    "    theme(legend.title = element_text(size = 16),\n",
    "          legend.text = element_text(size = 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_pca_var(data.pca, col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             title = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_pca_var(data.pca, axes = c(1, 3), col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             title = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_pca_var(data.pca, axes = c(2, 3), col.var = \"cos2\",\n",
    "             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n",
    "             title = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 16, repr.plot.height = 12)\n",
    "\n",
    "p1 <- ggplot(inds, aes(inds[, 1], inds[, 2], colour = pop.class)) +\n",
    "        geom_point() +\n",
    "        labs(x = paste(\"Dim 1 (\", round(eig.val[1, 2], 1), \"%)\", sep = \"\"),\n",
    "             y = paste(\"Dim 2 (\", round(eig.val[2, 2], 1), \"%)\", sep = \"\")) +\n",
    "        scale_color_brewer(palette=\"Set1\") +\n",
    "        theme(legend.position = \"none\")\n",
    "\n",
    "p2 <- ggplot(inds, aes(inds[, 1], inds[, 3], colour = pop.class)) +\n",
    "        geom_point() +\n",
    "        labs(x = paste(\"Dim 1 (\", round(eig.val[1, 2], 1), \"%)\", sep = \"\"),\n",
    "             y = paste(\"Dim 3 (\", round(eig.val[3, 2], 1), \"%)\", sep = \"\")) +\n",
    "        scale_color_brewer(palette=\"Set1\") +\n",
    "        theme(legend.position = \"none\")\n",
    "\n",
    "p3 <- ggplot(inds, aes(inds[, 1], inds[, 4], colour = pop.class)) +\n",
    "        geom_point() +\n",
    "        labs(x = paste(\"Dim 1 (\", round(eig.val[1, 2], 1), \"%)\", sep = \"\"),\n",
    "             y = paste(\"Dim 4 (\", round(eig.val[4, 2], 1), \"%)\", sep = \"\")) +\n",
    "        scale_color_brewer(palette=\"Set1\") +\n",
    "        theme(legend.position = \"none\")\n",
    "\n",
    "p4 <- ggplot(inds, aes(inds[, 2], inds[, 3], colour = pop.class)) +\n",
    "        geom_point() +\n",
    "        labs(x = paste(\"Dim 2 (\", round(eig.val[2, 2], 1), \"%)\", sep = \"\"),\n",
    "             y = paste(\"Dim 3 (\", round(eig.val[3, 2], 1), \"%)\", sep = \"\")) +\n",
    "        scale_color_brewer(palette=\"Set1\") +\n",
    "        theme(legend.title = element_text(size = 16),\n",
    "              legend.text = element_text(size = 13),\n",
    "              legend.position = \"left\")\n",
    "\n",
    "p5 <- ggplot(inds, aes(inds[, 2], inds[, 4], colour = pop.class)) +\n",
    "        geom_point() +\n",
    "        labs(x = paste(\"Dim 2 (\", round(eig.val[2, 2], 1), \"%)\", sep = \"\"),\n",
    "             y = paste(\"Dim 4 (\", round(eig.val[4, 2], 1), \"%)\", sep = \"\")) +\n",
    "        scale_color_brewer(palette=\"Set1\") +\n",
    "        theme(legend.position = \"none\")\n",
    "\n",
    "p6 <- ggplot(inds, aes(inds[, 3], inds[, 4], colour = pop.class)) +\n",
    "        geom_point() +\n",
    "        labs(x = paste(\"Dim 3 (\", round(eig.val[3, 2], 1), \"%)\", sep = \"\"),\n",
    "             y = paste(\"Dim 4 (\", round(eig.val[4, 2], 1), \"%)\", sep = \"\")) +\n",
    "        scale_color_brewer(palette=\"Set1\") +\n",
    "        theme(legend.position = \"none\")\n",
    "\n",
    "grid.arrange(p1, p2, p3, p4, p5, p6,\n",
    "             widths = c(1, 1, 1),\n",
    "             layout_matrix = rbind(c(1, 2, 3),\n",
    "                                   c(NA, 4, 5),\n",
    "                                   c(NA, NA, 6))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.pop.class <- spotify_data$pop.class\n",
    "spotify.key <- spotify_data$key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.pop.class.encoded <- as.numeric(spotify.pop.class) - 1\n",
    "spotify.pop.class.encoded[1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.key.encoded <- as.numeric(spotify.key) - 1\n",
    "spotify.key.encoded[1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.pop.class[1:15]\n",
    "spotify.key[1:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la classe de popularité, on a la correspondance :\n",
    "* 'A' -> 0\n",
    "* 'B' -> 1\n",
    "etc.\n",
    "\n",
    "Puis pour la clé :\n",
    "* 'A' -> 0\n",
    "* 'Ab' -> 1<br>\n",
    "$\\dots$\n",
    "* 'Gb' -> 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data$pop.class <- spotify.pop.class.encoded\n",
    "spotify_data$key <- spotify.key.encoded\n",
    "\n",
    "spotify_data$pop.class <- as.factor(spotify_data$pop.class) # pour la classification on reprend des facteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(spotify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.class <- spotify_data$pop.class\n",
    "y.reg <- spotify_data$popularity\n",
    "\n",
    "print(y.class[1:15])\n",
    "print(y.reg[1:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(glmnet)\n",
    "library(randomForest)\n",
    "library(rpart)\n",
    "library(e1071)\n",
    "library(partykit)\n",
    "library(nnet)\n",
    "library(VGAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(42)\n",
    "test.ratio <- 0.25\n",
    "npop <- nrow(spotify_data)\n",
    "nvar <- ncol(spotify_data)\n",
    "ntest <- ceiling(npop * test.ratio)\n",
    "testi <- sample(1:npop, ntest)\n",
    "appri <- setdiff(1:npop, testi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction de l'échantillon d'apprentissage\n",
    "X.train <- spotify_data[appri, -11] # on supprime popularity\n",
    "# construction de l'échantillon test\n",
    "X.test <- spotify_data[testi, -11]\n",
    "\n",
    "# vérification\n",
    "str(X.train)\n",
    "str(X.test)\n",
    "# summary(X.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols <- c(7, 10, 13) # variables qualitatives\n",
    "pre.proc.vals <- preProcess(X.train[, -cols], method = c(\"center\", \"scale\"))\n",
    "\n",
    "X.train.scaled <- data.frame(X.train)\n",
    "X.train.scaled[, -cols] <- predict(pre.proc.vals, X.train.scaled[, -cols])\n",
    "\n",
    "X.test.scaled <- data.frame(X.test)\n",
    "X.test.scaled[, -cols] <- predict(pre.proc.vals, X.test.scaled[, -cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.train.class <- y.class[appri]\n",
    "y.test.class <- y.class[testi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score <- function(table){\n",
    "    n <- nrow(table)\n",
    "    res <- 0\n",
    "    for(i in 1:n){\n",
    "        res <- res + table[i,i]/(sum(table[,i]))\n",
    "    }\n",
    "    res <- res/n\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.confusion.matrix <- function(y.true, y.pred) {\n",
    "    cm <- confusionMatrix(factor(y.pred), factor(y.true), dnn = c(\"Predicted\", \"Observed\"))\n",
    "\n",
    "    ggplot(as.data.frame(cm$table), aes(Predicted, sort(Observed, decreasing = T), fill = Freq)) +\n",
    "        geom_tile() +\n",
    "        geom_text(aes(label = Freq)) +\n",
    "        theme(legend.position = \"none\") +\n",
    "        scale_fill_gradient(low = \"white\", high = \"#4C72B0\") +\n",
    "        labs(x = \"Observed\", y = \"Predicted\") +\n",
    "        scale_x_discrete(labels = c(\"Classe A\", \"Classe B\", \"Classe C\", \"Classe D\")) +\n",
    "        scale_y_discrete(labels = c(\"Classe D\", \"Classe C\", \"Classe B\", \"Classe A\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mat <- model.matrix(pop.class ~ . - 1, data = X.train.scaled)\n",
    "x.mat2 <- model.matrix(pop.class ~ . - 1, data = X.test.scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans pénalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class.lr <- vglm(pop.class ~ ., family = multinomial, data = X.train.scaled, trace = TRUE)\n",
    "summary(class.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Rfast)\n",
    "\n",
    "prediction <- predict(class.lr, X.test.scaled, type = \"response\")\n",
    "pred.lr <- Rfast::rowMaxs(prediction) - 1\n",
    "\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "# table(y.test.class, maxs)\n",
    "plot.confusion.matrix(y.test.class, pred.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : les cellules suivantes sembleraient donner une régression logistique sans pénalisation mais nous avons plutôt utilisé la libraire `VGAM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class.lr.cv <- cv.glmnet(y = X.train$pop.class, x = x.mat, alpha = 0,\n",
    "#                          lambda = 10^c(-5, -6), family = \"multinomial\",\n",
    "#                          type.multinomial = \"grouped\")\n",
    "\n",
    "# class.lr.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# paste(\"CV estimate of lambda :\", round(class.lr.cv$lambda.1se, 3))\n",
    "# coef(class.lr.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.lr <- predict(class.lr.cv, newx = x.mat2, s = \"lambda.min\", type = \"class\")\n",
    "# options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "# plot.confusion.matrix(y.test.class, pred.lr)\n",
    "# table(pred.lr, y.test.class)\n",
    "# paste(\"Prediction error: \",\n",
    "#       round(100 * (1 - sum(diag(table(pred.lr, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.lr <- round(100 * (1 - sum(diag(table(pred.lr, y.test.class)))/ntest), 4)\n",
    "pred.error.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.logr <- round(recall.score(table(pred.lr, y.test.class)), 4)\n",
    "recall.score.logr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pénalisation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class.lasso <- glmnet(y = X.train.scaled$pop.class, x = x.mat, alpha = 1,\n",
    "                      family = \"multinomial\", type.multinomial = \"grouped\")\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "\n",
    "plot(class.lasso, xvar = \"lambda\", label = TRUE)\n",
    "legend(\"bottomleft\", legend = paste(1:ncol(x.mat), \" - \", colnames(x.mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class.lasso.cv <- cv.glmnet(y = X.train.scaled$pop.class, x = x.mat, alpha = 1,\n",
    "                            family = \"multinomial\", type.multinomial = \"grouped\")\n",
    "\n",
    "plot(class.lasso.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paste(\"CV estimate of lambda :\", round(class.lasso.cv$lambda.1se, 3))\n",
    "coef(class.lasso.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.lr.lasso <- predict(class.lasso.cv, newx = x.mat2, s = \"lambda.min\", type = \"class\")\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.lr.lasso)\n",
    "# table(pred.lr.lasso, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.lr.lasso, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.lasso <- round(100 * (1 - sum(diag(table(pred.lr.lasso, y.test.class)))/ntest), 4)\n",
    "pred.error.lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.lasso <- round(recall.score(table(pred.lr.lasso, y.test.class)), 4)\n",
    "recall.score.lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pénalisation Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class.ridge.cv <- cv.glmnet(y = X.train.scaled$pop.class, x = x.mat, alpha = 0,\n",
    "                            family = \"multinomial\", type.multinomial = \"grouped\")\n",
    "\n",
    "plot(class.ridge.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paste(\"CV estimate of lambda :\", round(class.ridge.cv$lambda.1se, 3))\n",
    "coef(class.ridge.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.lr.ridge <- predict(class.ridge.cv, newx = x.mat2, s = \"lambda.min\", type = \"class\")\n",
    "tab <- as.data.frame.matrix(table(pred.lr.ridge, y.test.class))\n",
    "tab <- rbind(c(0, 0, 0, 0), tab)\n",
    "rownames(tab) <- 0:3\n",
    "\n",
    "as.matrix(tab)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(as.matrix(tab)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est normal d'avoir une plus grande erreur de prévision à cause de la construction de la matrice (on n'avait pas de prévisions dans la classe A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.ridge <- round(100 * (1 - sum(diag(as.matrix(tab)))/ntest), 4)\n",
    "pred.error.ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.ridge <- round(recall.score(tab), 4)\n",
    "recall.score.ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pénalisation Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class.EN.cv <- cv.glmnet(y = X.train.scaled$pop.class, x = x.mat, alpha = 0.5,\n",
    "                         family = \"multinomial\", type.multinomial = \"grouped\")\n",
    "\n",
    "plot(class.EN.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paste(\"CV estimate of lambda :\", round(class.EN.cv$lambda.1se, 3))\n",
    "coef(class.EN.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.lr.EN <- predict(class.EN.cv, x.mat2, s = \"lambda.min\", type = \"class\")\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.lr.EN)\n",
    "# table(pred.lr.EN, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.lr.EN, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.EN <- round(100 * (1 - sum(diag(table(pred.lr.EN, y.test.class)))/ntest), 4)\n",
    "pred.error.EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.EN <- round(recall.score(table(pred.lr.EN, y.test.class)), 4)\n",
    "recall.score.EN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "eps <- 2e-02\n",
    "bestMtry <- tuneRF(X.train.scaled[, -13], X.train.scaled$pop.class, stepFactor = 1.5,\n",
    "                   improve = eps, ntree = 500, trace = TRUE, plot = TRUE)\n",
    "\n",
    "bestMtry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(bestMtry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.class <- randomForest(pop.class ~ ., data = X.train.scaled, mtry = 4,\n",
    "                         xtest = X.test.scaled[, -13], ytest = X.test.scaled$pop.class,\n",
    "                         ntree = 500, do.trace = 50, importance = TRUE)\n",
    "\n",
    "rf.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(round(importance(rf.class), 2)[, 4], decreasing = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rf.class <- rf.class$test$predicted\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.rf.class)\n",
    "# table(pred.rf, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.rf.class, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.rf <- round(100 * (1 - sum(diag(table(pred.rf.class, y.test.class)))/ntest), 4)\n",
    "pred.error.rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.rf <- round(recall.score(table(pred.rf.class, y.test.class)), 4)\n",
    "recall.score.rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control <- rpart.control(minsplit = 20,\n",
    "    minbucket = round(5 / 3),\n",
    "    maxdepth = 30,\n",
    "    cp = 0.001\n",
    ")\n",
    "\n",
    "tree.dis <- rpart(pop.class ~ ., data = X.train.scaled, method = 'class', control = control)\n",
    "plot(tree.dis)\n",
    "text(tree.dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.tree <- predict(tree.dis, X.test.scaled[, -13], type = \"class\")\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.tree)\n",
    "# table(pred.tree, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.tree, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 16, repr.plot.height = 12)\n",
    "plot(as.party(tree.dis), type = \"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.tree <- round(100 * (1 - sum(diag(table(pred.tree, y.test.class)))/ntest), 4)\n",
    "pred.error.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.tree <- round(recall.score(table(pred.tree, y.test.class)), 4)\n",
    "recall.score.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.lin.tune <- best.svm(pop.class ~ ., data = X.train.scaled, type = \"C\",\n",
    "                         kernel = \"lin\", cross = 5,\n",
    "                         cost = c(1, 1.5, 2, 2.5, 3, 3.5))\n",
    "svc.lin.tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.lin <- svm(pop.class ~ ., data = X.train.scaled, type = \"C\",\n",
    "               cost = svc.lin.tune$cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.lin <- predict(svc.lin, X.test.scaled[, -13])\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.lin)\n",
    "# table(pred.lin, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.lin, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.lin <- round(100 * (1 - sum(diag(table(pred.lin, y.test.class)))/ntest), 4)\n",
    "pred.error.lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.lin <- round(recall.score(table(pred.lin, y.test.class)), 4)\n",
    "recall.score.lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.poly.tune <- best.svm(pop.class ~ ., data = X.train.scaled, type = \"C\",\n",
    "                          kernel = \"poly\", cross = 5, coef0 = -1:1,\n",
    "                          cost = c(1, 1.5, 2, 2.5, 3, 3.5))\n",
    "svc.poly.tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.poly <- svm(pop.class ~ ., data = X.train.scaled, type = \"C\",\n",
    "                coef0 = svc.poly.tune$coef0,\n",
    "                cost = svc.poly.tune$cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.poly <- predict(svc.poly, X.test.scaled[, -13])\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.poly)\n",
    "# table(pred.poly, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.poly, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.poly <- round(100 * (1 - sum(diag(table(pred.poly, y.test.class)))/ntest), 4)\n",
    "pred.error.poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.poly <- round(recall.score(table(pred.poly, y.test.class)), 4)\n",
    "recall.score.poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.rad.tune <- best.svm(pop.class ~ ., data = X.train.scaled, type = \"C\",\n",
    "                         kernel = \"radial\", cost = c(0.1, 1, 1.5, 2),\n",
    "                         gamma = seq(0.02, 0.1, by = 0.02), cross = 5)\n",
    "svc.rad.tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.rad.tune$cost\n",
    "svc.rad.tune$gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.rad <- svm(pop.class ~ ., data = X.train.scaled, type = \"C\",\n",
    "               cost = svc.rad.tune$cost,\n",
    "               gamma = svc.rad.tune$gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rad <- predict(svc.rad, X.test.scaled[, -13])\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.rad)\n",
    "# table(pred.rad, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.rad, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.rad <- round(100 * (1 - sum(diag(table(pred.rad, y.test.class)))/ntest), 4)\n",
    "pred.error.rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.rad <- round(recall.score(table(pred.rad, y.test.class)), 4)\n",
    "recall.score.rad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.dis <- multinom(pop.class ~ ., data = X.train.scaled, decay = 1e-5, maxit = 1000)\n",
    "nnet.dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.nn <- predict(nnet.dis, X.test.scaled[, -13], type = \"class\")\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "\n",
    "plot.confusion.matrix(y.test.class, pred.nn)\n",
    "# table(pred.nn, y.test.class)\n",
    "paste(\"Prediction error: \",\n",
    "      round(100 * (1 - sum(diag(table(pred.nn, y.test.class)))/ntest), 1), \" %\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.error.nn <- round(100 * (1 - sum(diag(table(pred.nn, y.test.class)))/ntest), 4)\n",
    "pred.error.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall.score.nn <- round(recall.score(table(pred.nn, y.test.class)), 4)\n",
    "recall.score.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableau de comparaison :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors <- c(pred.error.lr, pred.error.lasso, pred.error.ridge, \n",
    "            pred.error.EN, pred.error.rf, pred.error.tree,\n",
    "            pred.error.lin, pred.error.poly, pred.error.rad, pred.error.nn)\n",
    "\n",
    "accuracy.scores <- 100 - errors\n",
    "\n",
    "recall.scores <- c(recall.score.logr, recall.score.lasso, recall.score.ridge,\n",
    "                   recall.score.EN, recall.score.rf, recall.score.tree,\n",
    "                   recall.score.lin, recall.score.poly, recall.score.rad,\n",
    "                   recall.score.nn)\n",
    "\n",
    "methods.class <- c(\"Logistic Regression\", \"Lasso\", \"Ridge\", \"Elastic Net\",\n",
    "                   \"Random Forest\", \"Decision Trees\", \"Linear SVC\",\n",
    "                   \"Polynomial SVC \", \"Radial SVC\", \"Neural Network\")\n",
    "\n",
    "class.comparison <- data.frame(Model = methods.class,\n",
    "                               Accuracy = accuracy.scores/100,\n",
    "                               Recall = recall.scores)\n",
    "class.comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class.comparison[order(class.comparison$Accuracy, decreasing = TRUE), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.train <- spotify_data[appri, -14] # on supprime pop.class\n",
    "X.test <- spotify_data[testi, -14]\n",
    "\n",
    "str(X.train)\n",
    "str(X.test)\n",
    "# summary(X.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols <- c(7, 10, 11)\n",
    "pre.proc.vals <- preProcess(X.train[, -cols], method = c(\"center\", \"scale\"))\n",
    "\n",
    "X.train.scaled <- data.frame(X.train)\n",
    "X.train.scaled[, -cols] <- predict(pre.proc.vals, X.train.scaled[, -cols])\n",
    "\n",
    "X.test.scaled <- data.frame(X.test)\n",
    "X.test.scaled[, -cols] <- predict(pre.proc.vals, X.test.scaled[, -cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.train.reg <- y.reg[appri]\n",
    "y.test.reg <- y.reg[testi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores <- vector(mode = \"numeric\", length = 10)\n",
    "r2.scores <- vector(mode = \"numeric\", length = 10)\n",
    "thresholding.scores <- vector(mode = \"numeric\", length = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.res <- function(x, y, titre = \"titre\") {\n",
    "    plot(x, y, col = \"blue\", xlim = c(0, 100), ylim = c(-100, 100),\n",
    "         ylab = \"Résidus\", xlab = \"Valeurs prédites\", main = titre, pch = 20)\n",
    "    # points(x2, y, col='red')\n",
    "    abline(h = 0, col = \"green\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.to.class <- function(y.pred){\n",
    "    n = length(y.pred)\n",
    "    y.reg.to.class <- vector(mode = \"integer\", length = n)\n",
    "    for (i in 1:n) {\n",
    "        if (y.pred[i] < 20) {\n",
    "            y.reg.to.class[i] = 3\n",
    "        } else if (20 <= y.pred[i] & y.pred[i] < 40) {\n",
    "            y.reg.to.class[i] = 2\n",
    "        } else if (40 <= y.pred[i] & y.pred[i] < 60) {\n",
    "            y.reg.to.class[i] = 1\n",
    "        } else {\n",
    "            y.reg.to.class[i] = 0\n",
    "        }\n",
    "    }\n",
    "    return (y.reg.to.class)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold.score <- function(y.pred.reg, y.true.class) {\n",
    "    y.reg.to.class <- reg.to.class(y.pred.reg)\n",
    "    pred.error <- round(1 - sum(diag(table(y.reg.to.class, y.true.class))/ntest), 4)\n",
    "    accuracy <- 1 - pred.error\n",
    "    return (accuracy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.regression.results <- function(y.true.reg, y.true.class, y.pred) {\n",
    "    print(paste(\"Mean Squared Error:\", round(sum((y.pred - y.true.reg)^2)/ntest, 4)))\n",
    "    print(paste(\"R2 Score:\", round(cor(y.true.reg, y.pred) ^ 2, 4)))\n",
    "    \n",
    "    preds <- data.frame(true = y.true.reg, predicted = y.pred)\n",
    "    \n",
    "    ggplot(preds, aes(x = true, y = predicted)) + geom_point(color = \"blue\") +\n",
    "        labs(x = \"Observations\", y = \"Prédictions\") +\n",
    "        geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\", size = 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression lineáire\n",
    "\n",
    "#### Sans pénalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mat <- model.matrix(popularity ~ . - 1, data = X.train.scaled)\n",
    "x.mat2 <- model.matrix(popularity ~ . - 1, data = X.test.scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.lm <- aov(popularity ~ ., data = X.train)\n",
    "summary(reg.lm)\n",
    "\n",
    "res.lm <- reg.lm$residuals\n",
    "fit.lm <- reg.lm$fitted.values\n",
    "\n",
    "plot.res(fit.lm, res.lm, \"Régression linéaire sans sélection de variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.lin.reg <- predict(reg.lm, newdata = X.test[, -11])\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.lin.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[1] <- round(sum((pred.lin.reg - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[1] <- round(cor(y.test.reg, pred.lin.reg)^2, 4)\n",
    "thresholding.scores[1] <- threshold.score(pred.lin.reg, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.lin <- reg.to.class(pred.lin.reg)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.lin)\n",
    "\n",
    "y.rtc.lin.accuracy <- threshold.score(pred.lin.reg, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.lin.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pénalisation LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.lasso <- glmnet(y = X.train.scaled$popularity, x = x.mat, alpha = 1)\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "\n",
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE)\n",
    "legend(\"bottomleft\", legend = paste(1:ncol(x.mat), \" - \", colnames(x.mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.lasso.cv <- cv.glmnet(y = X.train.scaled$popularity, x = x.mat, alpha = 1)\n",
    "\n",
    "plot(reg.lasso.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeur estimée\n",
    "paste(\"CV estimate of lambda :\", round(reg.lasso.cv$lambda.1se, 3))\n",
    "\n",
    "# modèle correspondant\n",
    "coef(reg.lasso.cv, s = \"lambda.1se\")  # Extraction des valeurs ajustées et des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.lasso <- predict(reg.lasso.cv, s = \"lambda.min\", newx = x.mat)\n",
    "res.lasso <- X.train.scaled$popularity - fit.lasso\n",
    "\n",
    "# Graphe des résidus\n",
    "options(repr.plot.width = 16, repr.plot.height = 9)\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "plot.res(fit.lm, res.lm, \"linéaire\")\n",
    "plot.res(fit.lasso, res.lasso, \"linéaire, pénalité L1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.reg.lasso <- predict(reg.lasso.cv, newx = x.mat2, s = \"lambda.min\")\n",
    "pred.reg.lasso <- pred.reg.lasso[, 1]\n",
    "\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.reg.lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[2] <- round(sum((pred.reg.lasso - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[2] <- round(cor(y.test.reg, pred.reg.lasso)^2, 4)\n",
    "thresholding.scores[2] <- threshold.score(pred.reg.lasso, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.lasso <- reg.to.class(pred.reg.lasso)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.lasso)\n",
    "\n",
    "y.rtc.lasso.accuracy <- threshold.score(pred.reg.lasso, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.lasso.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalisation Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.ridge.cv <- cv.glmnet(y = X.train.scaled$popularity, x = x.mat, alpha = 0)\n",
    "\n",
    "plot(reg.ridge.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"CV estimate of lambda :\", round(reg.ridge.cv$lambda.1se, 3))\n",
    "coef(reg.ridge.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.ridge <- predict(reg.ridge.cv, s = \"lambda.min\", newx = x.mat)\n",
    "res.ridge <- X.train.scaled$popularity - fit.ridge\n",
    "\n",
    "options(repr.plot.width = 16, repr.plot.height = 9)\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "plot.res(fit.lm, res.lm, \"linéaire\")\n",
    "plot.res(fit.ridge, res.ridge, \"linéaire, pénalité L2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.reg.ridge <- predict(reg.ridge.cv, newx = x.mat2, s = \"lambda.min\")\n",
    "pred.reg.ridge <- pred.reg.ridge[, 1]\n",
    "\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.reg.ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[3] <- round(sum((pred.reg.ridge - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[3] <- round(cor(y.test.reg, pred.reg.ridge)^2, 4)\n",
    "thresholding.scores[3] <- threshold.score(pred.reg.ridge, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.ridge <- reg.to.class(pred.reg.ridge)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.ridge)\n",
    "\n",
    "y.rtc.ridge.accuracy <- threshold.score(pred.reg.ridge, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.ridge.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalisation ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.EN.cv <- cv.glmnet(y = X.train.scaled$popularity, x = x.mat, alpha=0.5)\n",
    "\n",
    "plot(reg.EN.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"CV estimate of lambda :\", round(reg.EN.cv$lambda.1se, 3))\n",
    "coef(reg.EN.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.EN <- predict(reg.EN.cv, s = \"lambda.min\", newx = x.mat)\n",
    "res.EN <- X.train.scaled$popularity - fit.EN\n",
    "\n",
    "options(repr.plot.width = 16, repr.plot.height = 9)\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "plot.res(fit.lm, res.lm, \"linéaire\")\n",
    "plot.res(fit.EN, res.EN, \"linéaire, pénalité Elastic Net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.reg.EN <- predict(reg.EN.cv, newx = x.mat2, s = \"lambda.min\")\n",
    "pred.reg.EN <- pred.reg.EN[, 1]\n",
    "\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.reg.EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[4] <- round(sum((pred.reg.EN - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[4] <- round(cor(y.test.reg, pred.reg.EN)^2, 4)\n",
    "thresholding.scores[4] <- threshold.score(pred.reg.EN, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.EN <- reg.to.class(pred.reg.EN)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.EN)\n",
    "\n",
    "y.rtc.EN.accuracy <- threshold.score(pred.reg.EN, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.EN.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "eps <- 2e-05\n",
    "bestMtry <- tuneRF(X.train[, -10], X.train.scaled$popularity, mtryStart = 2,\n",
    "                   stepFactor = 1.5, improve = eps, ntree = 500, plot = TRUE)\n",
    "\n",
    "bestMtry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.reg <- randomForest(popularity ~ ., data = X.train.scaled, mtry = 9,\n",
    "                       xtest = X.test.scaled[, -10], ytest = X.test.scaled$popularity,\n",
    "                       ntree = 500, do.trace = 50, importance = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(round(importance(rf.reg), 2)[, 1], decreasing = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.rfr <- rf.reg$predicted\n",
    "res.rfr <- fit.rfr - X.train.scaled$popularity\n",
    "plot.res(fit.rfr, res.rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rf.reg <- rf.reg$test$predicted\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.rf.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[5] <- round(sum((pred.rf.reg - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[5] <- round(cor(y.test.reg, pred.rf.reg)^2, 4)\n",
    "thresholding.scores[5] <- threshold.score(pred.rf.reg, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.rf <- reg.to.class(pred.rf.reg)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.rf)\n",
    "\n",
    "y.rtc.rf.accuracy <- threshold.score(pred.rf.reg, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.rf.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control <- rpart.control(minsplit = 20,\n",
    "    minbucket = round(5 / 3),\n",
    "    maxdepth = 30,\n",
    "    cp = 0.001\n",
    ")\n",
    "\n",
    "tree.reg <- rpart(popularity ~ ., data = X.train.scaled, control = control)\n",
    "plot(tree.reg)\n",
    "text(tree.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmat <- xpred.rpart(tree.reg)\n",
    "xerr <- (xmat - X.train.scaled$popularity)^2\n",
    "CVerr <- apply(xerr, 2, sum)\n",
    "CVerr  #    CP           erreur\n",
    "\n",
    "# xmat_i = Y^chapeau_i est la valeur predite par le modèle qui n'a pas utilisé le\n",
    "# fold conentant l'observation i xerr = (Y_i - Y_i^chapeau)^2 pour i=1,...,n\n",
    "\n",
    "# L'erreur décroit avec la compléxité (ici ce n'est pas tout à fait le cas car\n",
    "# xpred.rpart fait de la validation croisée sur l'echantillon d'apprentissage)\n",
    "\n",
    "# En gras c'est les valeurs de gamma et à coté l'erreur estimée par validation\n",
    "# croisée. On choisit le gamma avec l'erreur la plus petite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche la valeur de *cp* correspondant à la plus petite erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp <- as.numeric(attributes(which.min(CVerr))$names)\n",
    "cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.reg <- rpart(popularity ~ ., data = X.train,\n",
    "                  control = rpart.control(cp = cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(as.party(tree.reg), type = \"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphe des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.tree <- predict(tree.reg, X.train.scaled[, -11])\n",
    "res.tree <- fit.tree - X.train.scaled$popularity\n",
    "plot.res(fit.tree, res.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.reg.tree <- predict(tree.reg, newdata = X.test.scaled[, -11])\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.reg.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[6] <- round(sum((pred.reg.tree - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[6] <- round(cor(y.test.reg, pred.reg.tree)^2, 4)\n",
    "thresholding.scores[6] <- threshold.score(pred.reg.tree, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.tree <- reg.to.class(pred.reg.tree)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.tree)\n",
    "\n",
    "y.rtc.tree.accuracy <- threshold.score(pred.reg.tree, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.tree.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm.reg.lin <- best.svm(popularity ~ ., data = X.train.scaled, cost = c(0.1, 1),\n",
    "                        kernel = \"linear\", cross = 5)\n",
    "\n",
    "svm.reg.lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.svmr <- svm.reg.lin$fitted\n",
    "res.svmr <- fit.svmr - X.train.scaled$popularity\n",
    "plot.res(fit.svmr, res.svmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.lin <- svm(popularity ~ ., data = X.train.scaled,\n",
    "               cost = svm.reg.lin$cost, kernel = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.svr.lin <- predict(svr.lin, newdata = X.test.scaled[, -11])\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.svr.lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[7] <- round(sum((pred.svr.lin - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[7] <- round(cor(y.test.reg, pred.svr.lin)^2, 4)\n",
    "thresholding.scores[7] <- threshold.score(pred.svr.lin, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.lin <- reg.to.class(pred.svr.lin)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.lin)\n",
    "\n",
    "y.rtc.lin.accuracy <- threshold.score(pred.svr.lin, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.lin.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm.reg.poly <- best.svm(popularity ~ ., data = X.train.scaled, cost = c(0.1, 1, 10),\n",
    "                         kernel = \"poly\", cross = 5)\n",
    "\n",
    "svm.reg.poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.svmr <- svm.reg.poly$fitted\n",
    "res.svmr <- fit.svmr - X.train.scaled$popularity\n",
    "plot.res(fit.svmr, res.svmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.poly <- svm(popularity ~ ., data = X.train.scaled,\n",
    "                cost = svm.reg.poly$cost, kernel = \"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.svr.poly <- predict(svr.poly, newdata = X.test.scaled[, -11])\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.svr.poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[8] <- round(sum((pred.svr.poly - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[8] <- round(cor(y.test.reg, pred.svr.poly)^2, 4)\n",
    "thresholding.scores[8] <- threshold.score(pred.svr.poly, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.poly <- reg.to.class(pred.svr.poly)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.poly)\n",
    "\n",
    "y.rtc.poly.accuracy <- threshold.score(pred.svr.poly, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.poly.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set.seed(2021)\n",
    "svm.reg.tune <- best.svm(popularity ~ ., data = X.train.scaled, cost = c(0.1, 1),\n",
    "                         gamma = seq(0.02, 0.1, 0.02), cross = 5)\n",
    "\n",
    "svm.reg.tune\n",
    "# plot(svm.reg.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.svmr <- svm.reg.tune$fitted\n",
    "res.svmr <- fit.svmr - X.train.scaled$popularity\n",
    "plot.res(fit.svmr, res.svmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.rad <- svm(popularity ~ ., data = X.train.scaled, kernel =\"radial\",\n",
    "               cost = svm.reg.tune$cost, gamma = svm.reg.tune$gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.svr.rad <- predict(svr.rad, newdata = X.test.scaled[, -11])\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.svr.rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[9] <- round(sum((pred.svr.rad - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[9] <- round(cor(y.test.reg, pred.svr.rad)^2, 4)\n",
    "thresholding.scores[9] <- threshold.score(pred.svr.rad, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.rad <- reg.to.class(pred.svr.rad)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.rad)\n",
    "\n",
    "y.rtc.rad.accuracy <- threshold.score(pred.svr.rad, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.rad.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseaux de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.tuned <- best.nnet(popularity ~ ., data = X.train.scaled, size = 4:5,\n",
    "                        decay = 1:10, maxit = 200, linout = TRUE)\n",
    "nnet.tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul et graphe des résidus\n",
    "fit.nnetr <- nnet.tuned$fitted\n",
    "res.nnetr <- fit.nnetr - X.train.scaled$popularity\n",
    "plot.res(fit.nnetr, res.nnetr, titre = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.nnetr <- predict(nnet.tuned, newdata = X.test.scaled[, -11])\n",
    "plot.regression.results(y.test.reg, y.test.class, pred.nnetr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.scores[10] <- round(sum((pred.nnetr - y.test.reg)^2)/ntest, 4)\n",
    "r2.scores[10] <- round(cor(y.test.reg, pred.nnetr)^2, 4)\n",
    "thresholding.scores[10] <- threshold.score(pred.nnetr, y.test.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.rtc.nn <- reg.to.class(pred.nnetr)\n",
    "plot.confusion.matrix(y.test.class, y.rtc.nn)\n",
    "\n",
    "y.rtc.nn.accuracy <- threshold.score(pred.nnetr, y.test.class)\n",
    "print(paste(\"Précision :\", y.rtc.nn.accuracy, sep = \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé des résultats en régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods.reg <- c(\"Linear Regression\", \"Lasso\", \"Ridge\", \"Elastic Net\",\n",
    "                 \"Random Forest\", \"Decision Trees\", \"Linear SVR\",\n",
    "                 \"Polynomial SVR\", \"Radial SVR\", \"Neural Network\")\n",
    "\n",
    "reg.comparison <- data.frame(\n",
    "    Model = methods.reg,\n",
    "    MSE = mse.scores,\n",
    "    R2 = r2.scores\n",
    ")\n",
    "\n",
    "reg.comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.comparison[order(reg.comparison$MSE, decreasing = FALSE), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison entre classification et régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifs <- class.comparison[, \"Accuracy\"]\n",
    "\n",
    "compare.table = data.frame(\n",
    "    Model = methods.class,\n",
    "    Classification = classifs,\n",
    "    Thresholding = thresholding.scores\n",
    ")\n",
    "\n",
    "compare.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.table[order(compare.table$Classification, decreasing = TRUE), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
