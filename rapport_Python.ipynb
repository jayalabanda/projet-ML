{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet de Machine Learning\n",
    "\n",
    "Notebook Python avec les codes utilisés pour le rapport final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from functions import *\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "plt.rcParams['font.size'] = 16\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize': (15, 6)})\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtenir les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = pd.read_csv(\"data/spotify-extr.txt\", sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description de l'ensemble du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables explicatives sont :\n",
    "* `valence` : la positivité de la chanson, vaut 1 si la chanson est très joyeuse, 0 sinon ;\n",
    "* `year` : année de sortie ;\n",
    "* `acousticness` : mesure \"l'acousticité\" de la chanson ;\n",
    "* `danceability` : mesure la \"dançabilite\" d'une chanson ;\n",
    "* `duration` : durée d'une chanson en millisecondes ;\n",
    "* `energy` : l'énergie de la chanson, vaut 1 si la chanson est très énergétique, 0 sinon ;\n",
    "* `intrumentalness` : taux d'instrumentalisation, vaut 1 s'il n'y a aucune voix présente dans la chanson, 0 sinon ; \n",
    "* `key` : tonalité de la musique (ex : A=la), ne prend pas en compte la distinction majeur/mineur ;\n",
    "* `liveness` : taux de prestation en live, vaut 1 si la chanson ne comporte que de la musique (sans sons à intérêts non-musicaux), 0 sinon ;\n",
    "* `loudness` : intensité sonore de la chanson\n",
    "* `mode` : variable binaire qui indique si la chanson commence par une progression d'accords majeure (1) ou non (0)\n",
    "* `speechiness` : taux de vocaux dans la chanson, vaut 1 si la chanson comporte de la voix tout le long, 0 sinon ;\n",
    "* `tempo` :  tempo de la chanson en beats par minute (bpm)\n",
    "\n",
    "Notre objectif consiste à prédire la valeur de `pop.class` et de `popularity`, c'est-à-dire la popularité d'une chanson, soit comme un entier entre 0 et 100, soit comme une classe $A$, $B$, $C$ ou $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qual = spotify_data[[\"pop.class\", \"mode\", \"key\"]]\n",
    "data_qual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme les variables qualitatives en catégories pour mieux traiter les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data[\"key\"] = pd.Categorical(spotify_data[\"key\"], ordered=False)\n",
    "spotify_data[\"mode\"] = pd.Categorical(spotify_data[\"mode\"], ordered=False)\n",
    "spotify_data[\"pop.class\"] = pd.Categorical(spotify_data[\"pop.class\"],\n",
    "                                           ordered=True,\n",
    "                                           categories=['D', 'C', 'B', 'A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses uni et multidimensionnelles\n",
    "\n",
    "## Variables qualitatives\n",
    "\n",
    "On commence par analyser les variables qualitatives `pop.class`, `key` et `mode`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Classe de popularité</b>\n",
    "\n",
    "Cette variable a été créée en amont de l'obtention des données. C'est notre variable à prédire en classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_class_count = data_qual[\"pop.class\"].value_counts().iloc[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=pop_class_count.index, y=pop_class_count.values)\n",
    "#plt.title(\"Fréquence des classes de popularité\", fontsize=14)\n",
    "plt.ylabel(\"Nombre d'occurences\", fontsize=13)\n",
    "plt.xlabel(\"Classe\", fontsize=13)\n",
    "save_fig(\"pop_class_frequencies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Clé</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "key_count = spotify_data['key'].value_counts(\n",
    "    normalize=True, sort=True, ascending=True) * 100\n",
    "y_ticks = spotify_data['key'].value_counts().index\n",
    "\n",
    "sns.barplot(x=key_count.values, y=y_ticks, data=key_count, orient='h')\n",
    "plt.xlabel(\"% d'occurences\", fontsize=12, weight='bold')\n",
    "plt.ylabel('Clé', fontsize=12, weight='bold')\n",
    "ax.set_xticks(ticks=range(0, 16, 1))\n",
    "ax.set_yticklabels(labels=y_ticks, fontsize=12)\n",
    "\n",
    "rects = ax.patches\n",
    "for rect in rects:\n",
    "    x_value = rect.get_width()\n",
    "    y_value = rect.get_y() + rect.get_height() / 2\n",
    "    label = f'{x_value:.1f}%'\n",
    "\n",
    "    plt.annotate(label, (x_value, y_value),\n",
    "                 xytext=(5, 0),\n",
    "                 textcoords=\"offset points\",\n",
    "                 va='center',\n",
    "                 ha='left')\n",
    "\n",
    "#plt.title(\"Distribution de 'key'\", fontsize=14)\n",
    "save_fig('keys_frequencies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='key', y='popularity', data=spotify_data)\n",
    "#plt.title(\"Popularité selon la clé\", fontsize=14)\n",
    "plt.ylabel(\"Popularité\")\n",
    "plt.xlabel(\"Clé\")\n",
    "save_fig(\"popularity_by_key\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='key', y='popularity', data=spotify_data)\n",
    "#plt.title(\"Popularité selon la clé\", fontsize=14)\n",
    "plt.ylabel(\"Popularité\")\n",
    "plt.xlabel(\"Clé\")\n",
    "#save_fig(\"popularity_by_key\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mode</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_count = spotify_data[\"mode\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=mode_count.index, y=mode_count.values)\n",
    "#plt.title(\"Fréquence des modes\", fontsize=14)\n",
    "plt.ylabel(\"Nombre d'occurences\", fontsize=13)\n",
    "plt.xlabel(\"Mode\", fontsize=13)\n",
    "save_fig(\"mode_frequencies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='mode', y='popularity', data=spotify_data)\n",
    "#plt.title(\"Fréquence des modes\", fontsize=14)\n",
    "plt.ylabel(\"Popularité selon le mode\", fontsize=13)\n",
    "plt.xlabel(\"Mode\", fontsize=13)\n",
    "save_fig(\"popularity_by_mode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='mode', y='popularity', data=spotify_data)\n",
    "#plt.title(\"Popularité selon la clé\", fontsize=14)\n",
    "plt.ylabel(\"Popularité\")\n",
    "plt.xlabel(\"Clé\")\n",
    "#save_fig(\"popularity_by_key\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regroupe toutes les variables qualitatives en un barplot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='mode', y='popularity', hue='key', data=spotify_data)\n",
    "#plt.title(\"Popularité selon la clé et le mode\", fontsize=14)\n",
    "save_fig(\"popularity_by_key_and_mode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='mode', y='popularity', hue='key', data=spotify_data)\n",
    "#plt.title(\"Popularité selon la clé et le mode\", fontsize=14)\n",
    "#save_fig(\"popularity_by_key_and_mode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables quantitatives\n",
    "\n",
    "On commence par visualiser la corrélation entre les variables quantitatives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quant = spotify_data[spotify_data.columns.difference(\n",
    "    ['key', 'mode', 'pop.class'], sort=False)]\n",
    "data_quant.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_quant.corr()\n",
    "cmap = sns.diverging_palette(240, 10, as_cmap=True)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corr_matrix, cmap=cmap, center=0, vmin=-1, vmax=1)\n",
    "#plt.title(\"Matrice de corrélation\")\n",
    "save_fig(\"correlation_square_matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique nous montre qu'il y a certaines variables qui ont une forte corrélation. Par exemple, il y a une forte corrélation négative entre les variables `energy` et `acousticness`. Cela a du sens vu que les chansons acoustiques sont plus tranquilles (moins énergiques) que celles qui ne sont pas acoustiques. De même, `energy` et `loudness` sont positivement corrélées, ce qui est attendu vu que les chansons bruyantes ont souvent plus d'énergie.\n",
    "<br>\n",
    "On voit aussi que plus une chanson est acoustique, moins elle est populaire, vu que les variables `acousticness` et `popularity` ont une forte corrélation négative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = np.abs(corr_matrix['popularity']).sort_values(ascending=False)\n",
    "print(\"Les variables les plus corrélées avec la variable 'popularity' sont : \")\n",
    "for i, row in enumerate(series):\n",
    "    if 0.2 <= row < 1:\n",
    "        print(f'{series.index[i]:17} --> {row: .2f} (abs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici leurs distributions avec boxplot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(spotify_data['energy'], spotify_data['acousticness'], alpha=.5)\n",
    "# plt.xlabel(\"Energy\")\n",
    "# plt.ylabel(\"Acousticness\")\n",
    "# plt.title(\"Acousticité des chansons en fonction de leur énergie\")\n",
    "# save_fig(\"acousticness_by_energy\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms_plot(data_quant, data_quant.columns, 4, 3)\n",
    "# save_fig(\"quantitative_data_histograms\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-poster')\n",
    "\n",
    "fig = plt.figure(figsize=(22, 28))\n",
    "outer = fig.add_gridspec(6, 2, wspace=0.1, hspace=0.5, left=0.03,\n",
    "                         right=0.98, bottom=0.03, top=0.98)\n",
    "\n",
    "a = 0\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        feature = data_quant.columns[a]\n",
    "        inner = outer[i, j].subgridspec(2, 1, wspace=0.2, hspace=0,\n",
    "                                        height_ratios=[0.15, 0.85])\n",
    "        axs = inner.subplots(sharex=True)\n",
    "\n",
    "        sns.boxplot(data=data_quant, x=feature, orient='h', ax=axs[0])\n",
    "        sns.histplot(data=data_quant, x=feature,\n",
    "                     bins=50 if a != 1 else 100,\n",
    "                     ax=axs[1], kde=True)\n",
    "\n",
    "        axs[0].spines['top'].set_color('black')\n",
    "        axs[0].spines['right'].set_color('black')\n",
    "        axs[0].spines['left'].set_color('black')\n",
    "\n",
    "        axs[1].set_title(\"Distribution de '\" + feature + \"'\", y=1.2, fontsize=14)\n",
    "        axs[1].spines['bottom'].set_color('black')\n",
    "        axs[1].spines['right'].set_color('black')\n",
    "        axs[1].spines['left'].set_color('black')\n",
    "\n",
    "        a += 1\n",
    "\n",
    "    #fig.suptitle('Distribution des variables quantitatives', y=1.01, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une étude plus approfondie de chaque variable quantitative :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Acousticness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_data = spotify_data.groupby(\n",
    "    'acousticness')['popularity'].mean().to_frame().reset_index()\n",
    "sns.scatterplot(x=ax_data['acousticness'],\n",
    "                y=ax_data['popularity'],\n",
    "                color='blue')\n",
    "#plt.title(\"Acousticité\")\n",
    "plt.ylabel('Popularité moyenne', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Danceability</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_data = spotify_data.groupby(\n",
    "    'danceability')['popularity'].mean().to_frame().reset_index()\n",
    "sns.scatterplot(x='danceability', y='popularity', data=ax_data, color='blue')\n",
    "#plt.title('Dançabilité')\n",
    "plt.ylabel('Popularité moyenne', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Duration</b>\n",
    "\n",
    "On convertit la durée des chansons en minutes pour en tirer plus d'informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data['duration'] = spotify_data['duration'] / 60000\n",
    "spotify_data['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data['duration'].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la chanson la plus longue dans le jeu de données dure 45 minutes, donc on choisit de séparer les chansons longues de chansons courtes au seuil de 8 minutes pour mieux voir les durées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_songs = spotify_data.loc[spotify_data['duration'] > 8]\n",
    "short_songs = spotify_data.loc[spotify_data['duration'] <= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(short_songs['duration'], kde=False)\n",
    "#plt.title(f'Chansons courtes (<=8 min) : {short_songs.shape[0]} chansons')\n",
    "plt.xticks(range(0, 9, 1))\n",
    "plt.xlim(0, 9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(long_songs['duration'], kde=False, bins=60)\n",
    "#plt.title(f'Chansons longues (>8 min) : {long_songs.shape[0]} chansons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "ax1_data = short_songs.groupby(\n",
    "    'duration')['popularity'].mean().to_frame().reset_index()\n",
    "ax1 = sns.scatterplot(x='duration',\n",
    "                      y='popularity',\n",
    "                      data=ax1_data,\n",
    "                      color='blue',\n",
    "                      ax=ax1)\n",
    "ax1.set_xticks(range(0, 9, 1))\n",
    "ax1.set_xlim(0, 9)\n",
    "ax1.set_title('Chansons courtes')\n",
    "\n",
    "ax2_data = long_songs.groupby(\n",
    "    'duration')['popularity'].mean().to_frame().reset_index()\n",
    "ax2 = sns.scatterplot(x=ax2_data['duration'],\n",
    "                      y=ax2_data['popularity'],\n",
    "                      color='green',\n",
    "                      ax=ax2)\n",
    "ax2.set_xticks(range(8, 49, 4))\n",
    "ax2.set_xlim(6, 50)\n",
    "ax2.set_title('Chansons longues')\n",
    "ax1.set_ylabel('Popularité moyenne', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Energy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_data = spotify_data.groupby(\n",
    "    'energy')['popularity'].mean().to_frame().reset_index()\n",
    "sns.scatterplot(x='energy', y='popularity', data=ax_data, color='blue')\n",
    "#plt.title('Énergie')\n",
    "plt.ylabel('Popularité moyenne', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instrumentalness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data['instrumentalness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.loc[spotify_data['tempo'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transformera la variable `instrumentalness` en trois sous-variables en raison de sa distribution inégale : il y a beaucoup de chansons ayant une valeur nulle d'instrumentalité, ce qui ne correspond pas vraiment avec la réalité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(spotify_data['instrumentalness'], kde=False, bins=50)\n",
    "# plt.vlines(0.1, ymin=0, ymax=7000, linestyles='dashed',\n",
    "#            linewidths=1., color='grey')\n",
    "# plt.vlines(0.95, ymin=0, ymax=7000, linestyles='dashed',\n",
    "#            linewidths=1., color='grey')\n",
    "# plt.annotate('1ère limite (0.10)', xy=(0.1, 6500),\n",
    "#              xytext=(0.2, 6500),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "# plt.annotate('2ème limite (0.95)', xy=(0.95, 6500),\n",
    "#              xytext=(0.7, 6500),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax_data = spotify_data.groupby(\n",
    "#     'instrumentalness')['popularity'].mean().to_frame().reset_index()\n",
    "# sns.scatterplot(x='instrumentalness', y='popularity',\n",
    "#                 data=ax_data, color='blue')\n",
    "# #plt.title('Instrumentalité')\n",
    "# plt.ylabel('Popularité moyenne', fontsize=12)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteria = [\n",
    "#     spotify_data['instrumentalness'].between(0, 0.1),\n",
    "#     spotify_data['instrumentalness'].between(0.100001, 0.95),\n",
    "#     spotify_data['instrumentalness'].between(0.950001, 1)\n",
    "# ]\n",
    "\n",
    "# values = np.arange(1, 4)\n",
    "# spotify_data['instrumentalness_criteria'] = np.select(criteria, values, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on supprime la variable `instrumentalness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del spotify_data['instrumentalness']\n",
    "\n",
    "# spotify_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.histplot(spotify_data['instrumentalness_criteria'], kde=False, bins=3)\n",
    "# plt.xticks(np.arange(1, 4))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spotify_data['instrumentalness_criteria'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Liveness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_data = spotify_data.groupby(\n",
    "    'liveness')['popularity'].mean().to_frame().reset_index()\n",
    "sns.scatterplot(x='liveness', y='popularity', data=ax_data, color='blue')\n",
    "#plt.title('liveness')\n",
    "plt.ylabel('Mean Popularity', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Popularity</b> (variable à prédire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 11))\n",
    "ax1 = sns.histplot(spotify_data['popularity'], ax=ax1, bins=50)\n",
    "ax2 = sns.histplot(spotify_data.loc[spotify_data['popularity'] > 0, 'popularity'],\n",
    "                   ax=ax2, bins=50)\n",
    "ax1.set_xlim(0, 100)\n",
    "ax2.set_xlim(0, 100)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_title('Haut : Toutes les données\\nBas : Popularité > 0', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il y a un nombre important de chansons ayant 0 comme popularité. En effet ces chansons sont proches de l'extraction de la base des données et donc leur popularité n'avait pas encore été déterminée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 4))\n",
    "ax = spotify_data.groupby('year')['popularity'].mean().plot()\n",
    "ax.set_title('Popularité moyenne au cours des années')\n",
    "ax.set_ylabel('Popularité moyenne', fontsize=12)\n",
    "ax.set_xlabel('Année')\n",
    "ax.xaxis.set_tick_params(labelsize=10)\n",
    "ax.set_xticks(range(1920, 2021, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tempo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='tempo', y='popularity', data=spotify_data, height=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.loc[spotify_data['tempo'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il y a 13 chansons pour lesquelles `tempo` vaut 0 ce qui n'est pas possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_tempo = spotify_data.loc[spotify_data['tempo'] > 0]['tempo']\n",
    "corrected_tempo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "ax = sns.histplot(spotify_data['tempo'], bins=200, kde=False)\n",
    "ax.set_ylabel('Fréquences', fontsize=12)\n",
    "\n",
    "ax.text(s='13\\nOutliers', x=5, y=40, fontdict={'size': 12, 'c': 'darkred'})\n",
    "ax.text(s='Valeurs sans 0', x=125, y=160,\n",
    "        fontdict={'size': 12, 'c': 'darkred'})\n",
    "ax.text(s='Médiane\\ncorrigée\\n114.55', x=116, y=40,\n",
    "        fontdict={'size': 10, 'c': 'darkgreen', 'weight': 'bold'})\n",
    "\n",
    "ax.axvline(x=114.55, ymin=0, ymax=0.7, color='green',\n",
    "           linestyle='dashed', linewidth=2)\n",
    "ax.axvline(x=35.37, ymin=0, ymax=1, color='orange',\n",
    "           linestyle='dashed', linewidth=3)\n",
    "ax.axvline(x=214.42, ymin=0, ymax=1, color='orange',\n",
    "           linestyle='dashed', linewidth=3)\n",
    "\n",
    "ax.annotate(\"\", xy=(35.37, 150), xytext=(214.42, 150),\n",
    "            arrowprops=dict(arrowstyle=\"<->\",\n",
    "                            color='r',\n",
    "                            linestyle='dashed',\n",
    "                            linewidth=2))\n",
    "ax.annotate(\"\", xy=(0, 30), xytext=(0, 50),\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            color='r',\n",
    "                            linestyle='dashed',\n",
    "                            linewidth=3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Year</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='year', y='popularity', data=spotify_data, height=10)\n",
    "plt.suptitle(\"Joint plot de la popularité selon l'année de sortie\", y=1.02)\n",
    "save_fig(\"jointplot_of_popularity_by_year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques plots de corrélations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.plotting import scatter_matrix\n",
    "\n",
    "# attributes = [\"acousticness\", \"energy\", \"loudness\", \"popularity\"]\n",
    "# scatter_matrix(spotify_data[attributes],\n",
    "#                alpha=0.2,\n",
    "#                figsize=(20, 15),\n",
    "#                diagonal='kde')\n",
    "# plt.suptitle(\"Nuage de points de quelques variables\", fontsize=20)\n",
    "# save_fig(\"scatter_matrix_plot\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux visualiser la durée de la chanson, nous avons décidé de lui appliquer le logarithme naturel afin de réduire les valeurs, tout en gardant l'ordre de croissance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spotify_data[\"log_duration\"] = np.log(spotify_data[\"duration\"])\n",
    "# spotify_data[\"log_duration\"].hist(bins=50)\n",
    "# plt.title(\"Log de la durée\")\n",
    "# save_fig(\"log_of_duration\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spotify_data[\"tempo_norm\"] = (\n",
    "#     spotify_data[\"tempo\"] -\n",
    "#     spotify_data[\"tempo\"].mean()) / spotify_data[\"tempo\"].std()\n",
    "# spotify_data[\"tempo_norm\"].hist(bins=50)\n",
    "# plt.title(\"Variable 'tempo' normalisée\")\n",
    "# save_fig(\"scaled_tempo\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spotify_data[\"dance_norm\"] = (\n",
    "#     spotify_data[\"danceability\"] -\n",
    "#     spotify_data[\"danceability\"].mean()) / spotify_data[\"danceability\"].std()\n",
    "# spotify_data[\"dance_norm\"].hist(bins=50)\n",
    "# plt.title(\"Variable 'danceability' normalisée\")\n",
    "# save_fig(\"scaled_danceability\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del spotify_data[\"duration\"]\n",
    "# del spotify_data[\"tempo\"]\n",
    "# del spotify_data[\"danceability\"]\n",
    "# spotify_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cellule prend assez de temps à s'exécuter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in ['key', 'mode']:\n",
    "    sns.pairplot(spotify_data, hue=i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(spotify_data)\n",
    "# #plt.suptitle(\"Pair plot des données\", fontsize=20, y=1.02)\n",
    "# save_fig(\"pairplot_of_dataset\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "attributs = [\n",
    "    feature for feature in spotify_data.keys()\n",
    "    if feature not in data_qual.keys()\n",
    "]\n",
    "attributs.remove('popularity')\n",
    "print(attributs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = spotify_data[attributs]\n",
    "X_scaled = scale(X_new)\n",
    "pca = PCA()\n",
    "C = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(pca.explained_variance_.size)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "var_ratio = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10), sharex=True)\n",
    "\n",
    "ax[0].bar(x, var_ratio)\n",
    "ax[0].plot(var_ratio, color='black')\n",
    "ax[0].set_ylabel(\"Pourcentage de la variance expliquée\", fontsize=16)\n",
    "#ax[0].set_title(\"Part de la variance expliquée\", fontsize=15)\n",
    "\n",
    "for p in ax[0].patches:\n",
    "    text = str(np.round(p.get_height(), 3) * 100)[:4] + '%'\n",
    "    ax[0].annotate(text=text,\n",
    "                   xy=(p.get_x() + p.get_width() / 2., p.get_height() + 0.01),\n",
    "                   fontsize='large', ha='center', va='center')\n",
    "\n",
    "ax[1].bar(x, cumsum, width=.7)\n",
    "ax[1].plot(x, cumsum)\n",
    "ax[1].set_ylabel(\"Variance partagée\", fontsize=16)\n",
    "#ax[1].set_title(\"Somme cumulée de la part de la variance\", fontsize=15)\n",
    "\n",
    "for p in ax[1].patches:\n",
    "    text = str(np.round(p.get_height(), 3) * 100)[:4] + '%'\n",
    "    ax[1].annotate(text=text,\n",
    "                   xy=(p.get_x() + p.get_width() / 2., p.get_height() + 0.01),\n",
    "                   fontsize='large', ha='center', va='center')\n",
    "\n",
    "fig.text(0.5, -0.01, \"Composantes Principales\", ha='center', fontsize=20)\n",
    "#plt.suptitle(\"Analyse de la variance des composantes principales\", fontsize=22)\n",
    "save_fig(\"explained_var_ratio_and_cumulative\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "plt.boxplot(C)\n",
    "plt.axhline(color='grey', linewidth=1, linestyle='--')\n",
    "#plt.title(\"Boxplot des variables de l'ACP\")\n",
    "save_fig(\"boxplot_of_variances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sélection de variables :\n",
    "On sélectionne les 6 premières composantes principales.\n",
    "Variance expliquée par les valeurs propres : 80% de variance expliquée à partir de 6 CP\n",
    "On observe un coude sur le graphe des variances expliquées à partir de la 6e CP.\n",
    "Boxplots : étendue des boxplots relativement stable à partir de la 5 ou 6e CP, la médiane des boxplots devient relativement identique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sc = sns.scatterplot(x=C[:, 0], y=C[:, 1], hue='pop.class',\n",
    "                     data=spotify_data, alpha=.7, legend=True)\n",
    "sc.legend().set_title('Classe de popularité')\n",
    "plt.axvline(color=\"grey\")\n",
    "plt.axhline(color=\"grey\")\n",
    "#plt.title(\"Nuage de points des individus de l'ACP\")\n",
    "save_fig(\"scatterplot_of_individuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Nuage de points des individus:\n",
    "On observe 2 groupes distincts : 1 grand et un plus petit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr_circle(X_new, pca, 1, 2)\n",
    "save_fig(\"pca_components_1_2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr_circle(X_new, pca, 1, 3)\n",
    "save_fig(\"pca_components_1_3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cercle des correlations  (dim 1 et dim 2):\n",
    "Axe des abscisses : Dimension 1\n",
    "Axe des ordonnées : Dimension 2\n",
    "\n",
    "Variables représentées par les flèches.\n",
    "\n",
    "Speechiness : entièrement expliquée par la dimension 2.\n",
    "Log_duration et speechiness sont très proches de l'axe des ordonnées : variables expliquées en majorité par la dimension 2.\n",
    "Instrumentalness, accousticness, loudness: essetiellement expliquées par la dimension 1.\n",
    "\n",
    "Accousticness et loudness : flèches sur le même axe. Variables inversement corrélées. En accord avec le graphe des corrélations.\n",
    "\n",
    "Axe 2 : \"divise\" les flèches en 2 ?\n",
    "A droite du graphe : dans les valeurs positives, on retrouve les chansons plus calmes / accoustiques / instrumentales\n",
    "A gauche du graphe : dans les valeurs négatives , on retrouve les chansons plus \"loud\", dançantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_pop_class = spotify_data[[\"pop.class\"]]\n",
    "spotify_key = spotify_data[[\"key\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "spotify_pop_class_encoded = ordinal_encoder.fit_transform(spotify_pop_class)\n",
    "spotify_pop_class_encoded = np.reshape(spotify_pop_class_encoded,\n",
    "                                       spotify_data.shape[0]).astype(int)\n",
    "print(spotify_pop_class_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "spotify_key_encoded = label_encoder.fit_transform(spotify_key.values.ravel())\n",
    "print(spotify_key_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data[\"key\"] = spotify_key_encoded\n",
    "spotify_data[\"pop.class\"] = spotify_pop_class_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    feature for feature in spotify_data.keys()\n",
    "    if feature not in ['popularity', 'pop.class']\n",
    "]\n",
    "print(features)\n",
    "\n",
    "X = spotify_data[features]\n",
    "y_class = spotify_data[[\"pop.class\"]]\n",
    "y_reg = spotify_data[[\"popularity\"]]\n",
    "y_class = y_class.values.ravel()\n",
    "y_reg = y_reg.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_reg[:5])\n",
    "print(y_class[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN_model(n_inputs, n_outputs, problem=None):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 input_dim=n_inputs,\n",
    "                                 activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(150, activation='relu'))\n",
    "    model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    \n",
    "    if problem == 'regression':\n",
    "        model.add(keras.layers.Dense(n_outputs,\n",
    "                                     activation='linear'))\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    elif problem == 'classification':\n",
    "        model.add(keras.layers.Dense(n_outputs,\n",
    "                                     activation='softmax'))\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'C', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_class, y_test_class = train_test_split(\n",
    "    X, y_class, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Popularity_DIC = {1: \"A\", 2: \"B\", 3: \"C\", 4: \"D\"}\n",
    "labels = Popularity_DIC.values()\n",
    "\n",
    "param = [{\"C\": [0.5, 1, 5, 10, 12, 15, 30]}]\n",
    "LM = GridSearchCV(LogisticRegression(penalty=\"l1\",\n",
    "                                     solver='saga',\n",
    "                                     multi_class='multinomial',\n",
    "                                     max_iter=4000),\n",
    "                  param, cv=10)\n",
    "LM.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "LM.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (LM.best_score_, LM.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_Predict = LM.predict(X_test_scaled)\n",
    "LM_Accuracy = accuracy_score(y_test_class, LM_Predict)\n",
    "print(\"Précision :\" + str(LM_Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_test_class, LM_Predict, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of LM\")\n",
    "save_fig(\"confusion_matrix_of_LM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\"C\": [0.5, 1, 5, 10, 12, 15, 30]}]\n",
    "LOVR = GridSearchCV(LogisticRegression(penalty=\"l1\",\n",
    "                                       solver='liblinear',\n",
    "                                       multi_class='ovr'),\n",
    "                    param, cv=10)\n",
    "LOVR.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "LOVR.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (LOVR.best_score_, LOVR.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOVR_Predict = LOVR.predict(X_test_scaled)\n",
    "LOVR_Accuracy = accuracy_score(y_test_class, LOVR_Predict)\n",
    "print(\"Précision :\" + str(LOVR_Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_test_class, LOVR_Predict, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of LOVR\")\n",
    "save_fig(\"confusion_matrix_of_LOVR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param=[{\"n_estimators\":np.arange(100,500,100),\"max_features\":list(range(2,10,1))}]\n",
    "param = [{\"max_features\": list(range(2, 10))}]\n",
    "RFC_Model = GridSearchCV(RandomForestClassifier(n_estimators=500, n_jobs=-1),\n",
    "                         param, cv=5, verbose=3)\n",
    "RFC_Model.fit(X_train, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (RFC_Model.best_score_, RFC_Model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Predict = RFC_Model.predict(X_test)\n",
    "RFC_Accuracy = accuracy_score(y_test_class, RFC_Predict)\n",
    "print(\"Précision : \" + str(RFC_Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_test_class, RFC_Predict, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of RFC\")\n",
    "save_fig(\"confusion_matrix_of_RFC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_rf = pd.DataFrame({\n",
    "#     'Importance': RFC_Model.feature_importances_,\n",
    "#     'Features': features\n",
    "# })\n",
    "\n",
    "# feature_df_rf.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, RFC_Predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\n",
    "    'min_samples_split': range(2, 203, 10),\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}]\n",
    "\n",
    "DT_Model = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                  param, cv=5, verbose=3)\n",
    "\n",
    "DT_Model.fit(X_train, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur score = %f, Meilleurs paramètres = %s\" %\n",
    "      (DT_Model.best_score_, DT_Model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Predict = DT_Model.predict(X_test)\n",
    "DT_Accuracy = accuracy_score(y_test_class, DT_Predict)\n",
    "print(\"Précision : \" + str(DT_Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_test_class, DT_Predict, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of Decision Trees\")\n",
    "save_fig(\"confusion_matrix_of_DT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_dt = pd.DataFrame({\n",
    "#     'Importance': DT_Model.feature_importances_,\n",
    "#     'Features': features\n",
    "# })\n",
    "\n",
    "# feature_df_dt.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_Model = LinearSVC(multi_class='ovr', max_iter=4000, random_state=42)\n",
    "LSVC_Model.fit(X_train_scaled, y_train_class)\n",
    "LSVC_Prediction = LSVC_Model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_test_class, LSVC_Prediction, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of LSVC OVR\")\n",
    "save_fig(\"confusion_matrix_of_LSVC_OVR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, LSVC_Prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crammer-Singer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_Model = LinearSVC(multi_class='crammer_singer',\n",
    "                       max_iter=4000,\n",
    "                       random_state=42)\n",
    "LSVC_Model.fit(X_train_scaled, y_train_class)\n",
    "LSVC_Prediction = LSVC_Model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_test_class, LSVC_Prediction, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of LSVC C-S\")\n",
    "save_fig(\"confusion_matrix_of_LSVC_CS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, LSVC_Prediction, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\n",
    "    \"C\": [0.5, 1., 2., 5., 10., 15., 30.]\n",
    "}]\n",
    "SVC_Model = GridSearchCV(SVC(), param, cv=5, verbose=3)\n",
    "SVC_Model.fit(X_train_scaled, y_train_class)\n",
    "\n",
    "SVC_Model.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (SVC_Model.best_score_, SVC_Model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_Predict = SVC_Model.predict(X_test_scaled)\n",
    "SVC_Accuracy = accuracy_score(y_test_class, SVC_Predict)\n",
    "print(\"Précision :\" + str(SVC_Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_test_class, SVC_Predict, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of LOVR\")\n",
    "save_fig(\"confusion_matrix_of_SVC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, SVC_Predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseaux de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_hidden = 10\n",
    "# n_features = 10\n",
    "# n_classes = 4\n",
    "# keras_model = Sequential()\n",
    "# keras_model.add(Dense(n_hidden, input_dim=n_features, activation='sigmoid'))\n",
    "# keras_model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# keras_model.compile(optimizer=SGD(lr=3),\n",
    "#                     loss='categorical_crossentropy',\n",
    "#                     metrics=['accuracy'])\n",
    "# history = keras_model.fit(X_train, y_train, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X_train.shape[1], 4\n",
    "model = get_NN_model(n_inputs, n_outputs, 'classification')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = MM_scaler.fit_transform(X_train)\n",
    "X_test_scaled = MM_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train_class, epochs=200, batch_size=30,\n",
    "                    validation_data=(X_test_scaled, y_test_class), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot_class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_Predict = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "plot_cf_matrix(y_test_class, NN_Predict, classes, cmap='Blues', draw_mosaic=False)\n",
    "#plt.title(\"Confusion Matrix of NN\")\n",
    "save_fig(\"confusion_matrix_of_NN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, NN_Predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "\n",
    "reg_metrics = (mean_squared_error, r2_score, explained_variance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_Model = LinearRegression()\n",
    "LR_Model.fit(X_train, y_train_reg)\n",
    "LR_Predict = LR_Model.predict(X_test)\n",
    "\n",
    "plot_results(reg_metrics, y_test_reg, y_test_class, LR_Predict)\n",
    "#plt.title(\"Results of Linear Regression Predictions\")\n",
    "save_fig(\"results_of_LR_predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Model = RandomForestRegressor()\n",
    "RF_Model.fit(X_train, y_train_reg)\n",
    "RF_Predict = RF_Model.predict(X_test)\n",
    "\n",
    "plot_results(reg_metrics, y_test_reg, y_test_class, RF_Predict)\n",
    "#plt.title(\"Results of Random Forest Predictions\")\n",
    "save_fig(\"results_of_RF_predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation par validation croisée de la valeur de *max_features* et *min_samples_split*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\n",
    "    \"max_features\": list(range(2, 10)),\n",
    "    \"min_samples_split\": list(range(2, 14))\n",
    "}]\n",
    "\n",
    "RF_Model_Optim = GridSearchCV(RandomForestRegressor(), param, cv=5, n_jobs=-1)\n",
    "RF_Optim = RF_Model_Optim.fit(X_train, y_train_reg)\n",
    "RF_Predict_Optim = RF_Optim.predict(X_test)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (1. - RF_Optim.best_score_, RF_Optim.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(reg_metrics, y_test_reg, y_test_class, RF_Predict_Optim)\n",
    "#plt.title(\"Results of Random Forest Predictions with Optimal Parameters\")\n",
    "save_fig(\"results_of_RF_predictions_optim\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_rf = pd.DataFrame({\n",
    "#     'Importance': RF_Model.feature_importances_,\n",
    "#     'Features': features\n",
    "# })\n",
    "\n",
    "# feature_df_rf.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Model = DecisionTreeRegressor()\n",
    "DT_Model.fit(X_train, y_train_reg)\n",
    "DT_Predict = DT_Model.predict(X_test)\n",
    "\n",
    "plot_results(reg_metrics, y_test_reg, y_test_class, DT_Predict)\n",
    "#plt.title(\"Results of Decision Tree Predictions\")\n",
    "save_fig(\"results_of_DT_predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation par validation croisée de la valeur de *max_depth* et *min_samples_split*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\n",
    "    \"max_depth\": list(range(2, 10)),\n",
    "    \"min_samples_split\": list(range(2, 10))\n",
    "}]\n",
    "\n",
    "DT_Model_Optim = GridSearchCV(DecisionTreeRegressor(), param, cv=10, n_jobs=-1)\n",
    "DT_Optim = DT_Model_Optim.fit(X_train, y_train_reg)\n",
    "DT_Predict_Optim = DT_Optim.predict(X_test)\n",
    "# paramètres optimaux\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (1. - DT_Optim.best_score_, DT_Optim.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(reg_metrics, y_test_reg, y_test_class, DT_Predict_Optim)\n",
    "#plt.title(\"Results of Decision Tree Predictions with Optimal Parameters\")\n",
    "save_fig(\"results_of_DT_predictions_optim\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_dt = pd.DataFrame({\n",
    "#     'Importance': DT_Model.feature_importances_,\n",
    "#     'Features': features\n",
    "# })\n",
    "\n",
    "# feature_df_dt.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVR_Model = LinearSVR()\n",
    "LSVR_Model.fit(X_train_scaled, y_train_reg)\n",
    "LSVR_Predict = LSVR_Model.predict(X_test_scaled)\n",
    "\n",
    "plot_results(reg_metrics, y_test_reg, y_test_class, LSVR_Predict)\n",
    "#plt.title(\"Results of Linear SVR Predictions\")\n",
    "save_fig(\"results_of_LSVR_predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation de la pénalisation (paramètre $C$) par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\n",
    "    \"C\": [0.4, 0.5, 0.6, 0.8, 1., 1.4]\n",
    "}]\n",
    "\n",
    "LSVR_Model_Optim = GridSearchCV(LinearSVR(), param, cv=10)\n",
    "LSVR_Optim = LSVR_Model_Optim.fit(X_train_scaled, y_train_reg)\n",
    "LSVR_Predict_Optim = LSVR_Optim.predict(X_test_scaled)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (1. - LSVR_Optim.best_score_, LSVR_Optim.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(reg_metrics, y_test_reg, y_test_class, LSVR_Predict_Optim)\n",
    "#plt.title(\"Results of Linear SVR Predictions with Optimal Parameter\")\n",
    "save_fig(\"results_of_LSVR_predictions_optim\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_lsvr = pd.DataFrame({\n",
    "#     'Coefficients': LSVR_Model.coef_,\n",
    "#     'Features': features\n",
    "# })\n",
    "\n",
    "# feature_df_lsvr.sort_values(by='Coefficients', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_Model = SVR()\n",
    "SVR_Model.fit(X_train_scaled, y_train_reg)\n",
    "SVR_Predict = SVR_Model.predict(X_test_scaled)\n",
    "\n",
    "plot_results(reg_metrics, y_test_reg, y_test_class, SVR_Predict)\n",
    "#plt.title(\"Results of SVR Predictions\")\n",
    "save_fig(\"results_of_SVR_predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation de la pénalisation (paramètre $C$) par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\n",
    "    \"C\": [0.4, 0.5, 0.6, 0.8, 1, 1.4]\n",
    "}]\n",
    "\n",
    "SVR_Model_Optim = GridSearchCV(SVR(), param, cv=10)\n",
    "SVR_Optim = SVR_Model_Optim.fit(X_train_scaled, y_train_reg)\n",
    "SVR_Predict_Optim = SVR_Optim.predict(X_test_scaled)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (1. - SVR_Optim.best_score_, SVR_Optim.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(reg_metrics, y_test_reg, y_test_class, SVR_Predict_Optim)\n",
    "#plt.title(\"Results of SVR Predictions with Optimal Parameter\")\n",
    "save_fig(\"results_of_SVR_predictions_optim\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseaux de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X_train.shape[1], 1\n",
    "model = get_NN_model(n_inputs, n_outputs, 'regression')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = MM_scaler.fit_transform(X_train)\n",
    "X_test_scaled = MM_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train_reg, epochs=200, batch_size=30,\n",
    "                    validation_data=(X_test_scaled, y_test_reg), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "#plt.ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot_reg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_Predict = model.predict(X_test_scaled)\n",
    "\n",
    "plot_results(reg_metrics, y_test_reg, y_test_class, NN_Predict)\n",
    "#plt.title(\"Results of NN Predictions\")\n",
    "save_fig(\"results_of_NN_predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "428.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
